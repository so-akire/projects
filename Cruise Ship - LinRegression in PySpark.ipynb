{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyundai wants to predict the crew numbers will be needed in the future cruise ships they want to produce with certain specs. In this case, I use Linear Regression on the past data of different ships specs and its crew numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('ship').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('cruise_ship_info.csv', header=True, inferSchema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55)\n",
      "\n",
      "\n",
      "Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55)\n",
      "\n",
      "\n",
      "Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7)\n"
     ]
    }
   ],
   "source": [
    "for row in data.head(3):\n",
    "    print('\\n')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "ships.\n",
    "\n",
    "\n",
    "Variables/Columns\n",
    "Ship Name     1-20\n",
    "Cruise Line   21-40\n",
    "Age (as of 2013)   46-48\n",
    "Tonnage (1000s of tons)   50-56\n",
    "passengers (100s)   58-64\n",
    "Length (100s of feet)  66-72\n",
    "Cabins  (100s)   74-80\n",
    "Passenger Density   82-88\n",
    "Crew  (100s)   90-96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journey\n",
      "Azamara\n",
      "6\n",
      "30.276999999999997\n",
      "6.94\n",
      "5.94\n",
      "3.55\n",
      "42.64\n",
      "3.55\n"
     ]
    }
   ],
   "source": [
    "for item in data.head():\n",
    "    print (item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n",
      "|summary|Ship_name|Cruise_line|               Age|           Tonnage|       passengers|           length|            cabins|passenger_density|             crew|\n",
      "+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n",
      "|  count|      158|        158|               158|               158|              158|              158|               158|              158|              158|\n",
      "|   mean| Infinity|       null|15.689873417721518| 71.28467088607599|18.45740506329114|8.130632911392404| 8.830000000000005|39.90094936708861|7.794177215189873|\n",
      "| stddev|      NaN|       null| 7.615691058751413|37.229540025907866|9.677094775143416|1.793473548054825|4.4714172221480615| 8.63921711391542|3.503486564627034|\n",
      "|    min|Adventure|    Azamara|                 4|             2.329|             0.66|             2.79|              0.33|             17.7|             0.59|\n",
      "|    max|Zuiderdam|   Windstar|                48|             220.0|             54.0|            11.82|              27.0|            71.43|             21.0|\n",
      "+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max,min\n",
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quantitative= data.select(\n",
    " 'Tonnage',\n",
    " 'passengers',\n",
    " 'length',\n",
    " 'cabins',\n",
    " 'crew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+------------------+-----------------+\n",
      "|summary|           Tonnage|       passengers|           length|            cabins|             crew|\n",
      "+-------+------------------+-----------------+-----------------+------------------+-----------------+\n",
      "|  count|               158|              158|              158|               158|              158|\n",
      "|   mean| 71.28467088607599|18.45740506329114|8.130632911392404| 8.830000000000005|7.794177215189873|\n",
      "| stddev|37.229540025907866|9.677094775143416|1.793473548054825|4.4714172221480615|3.503486564627034|\n",
      "|    min|             2.329|             0.66|             2.79|              0.33|             0.59|\n",
      "|    max|             220.0|             54.0|            11.82|              27.0|             21.0|\n",
      "+-------+------------------+-----------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_quantitative.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['Tonnage']<50).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter((data['Tonnage']>=50 )& (data['Tonnage']<=100)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['Tonnage']>100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['cabins']<=5.00).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter((data['cabins']>5.00 ) & (data['cabins']<=10.00)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(data['cabins']>10.00).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import stddev #unresolved\n",
    "cl_sd=data.groupBy(\"Cruise_line\").agg(stddev('Tonnage').alias('Tonnage'))\n",
    "cl_sd2=cl_sd.select('Cruise_line', format_number('Tonnage',2).alias('Tonnage'))\n",
    "cl_mean.join(cl_sd2, Cruise_line=Cruise_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datac=data.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datac.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention! outputCol should be exactly 'features' with small f. Otherwise the fit  method won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[ \n",
    "                                        'Tonnage',\n",
    "                                         'passengers',\n",
    "                                         'length',\n",
    "                                         'cabins',\n",
    "                                         'passenger_density',\n",
    "                                         'crew'],\n",
    "                            outputCol='features') #small f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=assembler.transform(datac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[30.2769999999999...|\n",
      "|[30.2769999999999...|\n",
      "|[47.262,14.86,7.2...|\n",
      "|[110.0,29.74,9.53...|\n",
      "|[101.353,26.42,8....|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data=output.select(\"features\",'crew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[30.2769999999999...|3.55|\n",
      "|[30.2769999999999...|3.55|\n",
      "|[47.262,14.86,7.2...| 6.7|\n",
      "|[110.0,29.74,9.53...|19.1|\n",
      "|[101.353,26.42,8....|10.0|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepared_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD,testD=prepared_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              107|\n",
      "|   mean|7.987943925233647|\n",
      "| stddev|3.307928080461424|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainD.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|                51|\n",
      "|   mean|  7.38764705882353|\n",
      "| stddev|3.8852143252259816|\n",
      "|    min|              0.59|\n",
      "|    max|              19.1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testD.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression Model object\n",
    "lr = LinearRegression(labelCol='crew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the train data and call this model lrModel\n",
    "lrModel = lr.fit(trainD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:{} Intercept:[1.232535941970415e-15,-4.891574761936937e-16,-2.769408917566102e-14,-1.9762901078887148e-14,-2.389899693503025e-15,1.0000000000000262]\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients:{}\", \"Intercept:{}\".format(lrModel.coefficients, lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result=lrModel.evaluate(testD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-3.01980662698042...|\n",
      "|-3.15303338993544...|\n",
      "|-1.17683640610266...|\n",
      "|-5.35127497869325...|\n",
      "|2.065014825802791...|\n",
      "|1.687538997430238...|\n",
      "|3.819167204710538...|\n",
      "|3.774758283725532...|\n",
      "|-1.82076576038525...|\n",
      "|-1.68753899743023...|\n",
      "|-9.76996261670137...|\n",
      "|-1.02140518265514...|\n",
      "|-6.21724893790087...|\n",
      "|6.217248937900877...|\n",
      "|-6.75015598972095...|\n",
      "|-2.75335310107038...|\n",
      "|-1.42108547152020...|\n",
      "|3.552713678800501...|\n",
      "|-7.99360577730112...|\n",
      "|-1.77635683940025...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data=testD.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lrModel.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[3.341,0.66,2.79,...|0.5900000000000302|\n",
      "|[5.35,1.67,4.4,0....|0.8800000000000315|\n",
      "|[10.0,2.08,4.4,1....|1.6000000000000119|\n",
      "|[12.5,3.94,4.36,0...|1.4600000000000535|\n",
      "|[16.8,2.96,5.14,1...|1.9699999999999793|\n",
      "|[16.8,2.96,5.14,1...| 2.099999999999983|\n",
      "|[25.0,3.82,5.97,1...| 2.949999999999962|\n",
      "|[25.0,3.88,5.97,1...|2.8699999999999624|\n",
      "|[25.0,7.76,6.22,3...|3.8500000000000183|\n",
      "|[30.2769999999999...| 4.000000000000017|\n",
      "|[30.2769999999999...|3.7300000000000098|\n",
      "|[30.2769999999999...|  3.73000000000001|\n",
      "|[30.2769999999999...| 3.550000000000006|\n",
      "|[38.0,7.49,6.74,3...| 4.599999999999993|\n",
      "|[40.0530000000000...|7.5000000000000675|\n",
      "|[42.0,14.8,7.13,7...| 6.800000000000027|\n",
      "|[42.0,15.04,7.08,...| 6.300000000000014|\n",
      "|[45.0,11.78,7.54,...| 5.199999999999997|\n",
      "|[46.0,7.0,6.7,1.8...| 4.470000000000008|\n",
      "|[46.052,14.52,7.2...| 6.600000000000017|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.8980613315179705e-14\n",
      "MSE: 1.519488214427565e-27\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {}\".format(test_result.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_result.meanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
